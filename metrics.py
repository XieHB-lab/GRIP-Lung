import numpy as np
from sklearn.metrics import (
    mean_squared_error,
    r2_score,
    accuracy_score,
    precision_score,
    recall_score,
    f1_score
)


def evaluate(y_true, y_pred):
    """
    Evaluate regression and derived classification performance metrics.

    This function computes standard regression metrics on continuous
    gene expression values, as well as classification metrics obtained
    by binarizing expression values (positive vs. non-positive).

    Parameters
    ----------
    y_true : numpy.ndarray
        Ground-truth gene expression values.
    y_pred : numpy.ndarray
        Predicted gene expression values generated by the model.

    Returns
    -------
    mse : float
        Mean squared error (MSE).
    rmse_mean : float
        Root mean squared error normalized by the mean of y_true.
    rmse_std : float
        Root mean squared error normalized by the standard deviation of y_true.
    r2 : float
        Coefficient of determination (RÂ² score).
    acc : float
        Classification accuracy after binarization.
    prec : float
        Macro-averaged precision after binarization.
    rec : float
        Macro-averaged recall after binarization.
    f1 : float
        Macro-averaged F1 score after binarization.
    """

    # --------------------------------------------------------------
    # Regression metrics
    # --------------------------------------------------------------
    mse = mean_squared_error(y_true, y_pred)
    rmse = np.sqrt(mse)

    # Normalize RMSE by mean and standard deviation of true values
    rmse_mean = rmse / (abs(np.mean(y_true)) + 1e-8)
    rmse_std  = rmse / (np.std(y_true) + 1e-8)

    # Coefficient of determination
    r2 = r2_score(y_true, y_pred)

    # --------------------------------------------------------------
    # Convert continuous expression values to binary labels
    # Positive (> 0) vs. non-positive (<= 0)
    # --------------------------------------------------------------
    y_true_bin = (y_true > 0).astype(int).flatten()
    y_pred_bin = (y_pred > 0).astype(int).flatten()

    # --------------------------------------------------------------
    # Classification metrics
    # --------------------------------------------------------------
    acc  = accuracy_score(y_true_bin, y_pred_bin)
    prec = precision_score(
        y_true_bin, y_pred_bin,
        average="macro",
        zero_division=0
    )
    rec  = recall_score(
        y_true_bin, y_pred_bin,
        average="macro",
        zero_division=0
    )
    f1   = f1_score(
        y_true_bin, y_pred_bin,
        average="macro",
        zero_division=0
    )

    return mse, rmse_mean, rmse_std, r2, acc, prec, rec, f1

